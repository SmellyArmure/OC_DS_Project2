{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet 2 : Analyse des données de systèmes éducatifs\n",
    "\n",
    "## 0. Importations des modules et des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTATIONS\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "#% matplotlib notebook\n",
    "# graphes interactifs\n",
    "import re\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from collections import Counter\n",
    "from IPython.display import Image\n",
    "#import scipy.stats as st\n",
    "#import statsmodels.api as sm\n",
    "#from sklearn.datasets import load_iris\n",
    "#iris_df_ori = load_iris()\n",
    "\n",
    "####     A ESSAYER      #######################################################\n",
    "# GRAPHES INTERACTIFS\n",
    "\n",
    "\n",
    "# POUR LES GRAPHIQUES\n",
    "# % matplotlib inline \n",
    "# plt.rcParams['figure.figsize'] = [9.5, 6] # ajuster la taille\n",
    "\n",
    "# POUR DESACTIVER LA TOOLBOX GRAPHES TOP GRANDS\n",
    "# %%javascript\n",
    "# IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "#     return false;\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FONCTION SORTANT UN DATAFRAME D'INFOS (complémentaire du describe)\n",
    "\n",
    "def desc_bis (df):\n",
    "    nb_li = df.index.size\n",
    "    nb_col = df.columns.size\n",
    "    tot = nb_li*nb_col    \n",
    "    infos = pd.DataFrame(df.dtypes).T.rename(index={0:'Type'}) \n",
    "    infos = infos.append(pd.DataFrame(df.isna().sum()).T.rename(index={0:'null'}))\n",
    "    return infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infos (df):\n",
    "    nb_li = df.shape[0]\n",
    "    nb_co = df.shape[1]\n",
    "    t = np.empty(nb_li)\n",
    "    t.fill(nb_li)\n",
    "    df_l_null = pd.DataFrame(df.T.isna().sum()) # tableau du nbe de nul par lignes (+800 000 lignes)\n",
    "    df_c_null = pd.DataFrame(df.isna().sum()) # tableau du nbe de nul par colonnes (+65 colonnes)\n",
    "    \n",
    "    # nbe de lignes sans 'null'\n",
    "    al = len([x for x in df_l_null[0] if x==0])\n",
    "    nb_ss_null = pd.DataFrame([al]).rename(index={0:'lign_ss_null'}).T\n",
    "    pct_ss_null = pd.DataFrame([al*100/nb_li]).rename(index={0:'lign_ss_null'}).T\n",
    "    # nbe de lignes 'null'\n",
    "    bl = len([x for x in df_l_null[0] if x==nb_co])\n",
    "    nb_null = pd.DataFrame([bl]).rename(index={0:'lign_null'}).T\n",
    "    pct_null = pd.DataFrame([bl*100/nb_li]).rename(index={0:'lign_null'}).T\n",
    "    # nbe de lignes mixtes\n",
    "    cl = len([x for x in df_l_null[0] if (x!=0 and x!=nb_co)])\n",
    "    nb_mix = pd.DataFrame([cl]).rename(index={0:'lign_mix'}).T\n",
    "    pct_mix = pd.DataFrame([cl*100/nb_li]).rename(index={0:'lign_mix'}).T\n",
    "    infos_nb = pd.concat([nb_ss_null, nb_null, nb_mix],axis=1, sort=False).rename(index={0:'nb'})\n",
    "    infos_pct = pd.concat([pct_ss_null, pct_null, pct_mix],axis=1, sort=False).rename(index={0:'pct'})\n",
    "    infos_l = pd.concat([infos_nb,infos_pct], sort=False)\n",
    "    # nbe de lignes total\n",
    "    infos_l[\"lign_tot\"] = [infos_l.T['nb'].sum(), infos_l.T['pct'].sum()]\n",
    "    \n",
    "    # nbe de colonnes sans 'null'\n",
    "    ac = len([x for x in df_c_null[0] if x==0])\n",
    "    nb_ss_null = pd.DataFrame([ac]).rename(index={0:'col_ss_null'}).T\n",
    "    pct_ss_null = pd.DataFrame([ac*100/nb_co]).rename(index={0:'col_ss_null'}).T\n",
    "    # nbe de colonnes 'null'\n",
    "    bc = len([x for x in df_c_null[0] if x==nb_li])\n",
    "    nb_null = pd.DataFrame([bc]).rename(index={0:'col_null'}).T\n",
    "    pct_null = pd.DataFrame([bc*100/nb_co]).rename(index={0:'col_null'}).T\n",
    "    # nbe de colonnes mixtes\n",
    "    cc = len([x for x in df_c_null[0] if (x!=0 and x!=nb_li)])\n",
    "    nb_mix = pd.DataFrame([cc]).rename(index={0:'col_mix'}).T\n",
    "    pct_mix = pd.DataFrame([cc*100/nb_co]).rename(index={0:'col_mix'}).T\n",
    "    infos_nb = pd.concat([nb_ss_null, nb_null, nb_mix],axis=1, sort=False).rename(index={0:'nb'})\n",
    "    infos_pct = pd.concat([pct_ss_null, pct_null, pct_mix],axis=1, sort=False).rename(index={0:'pct'})\n",
    "    infos_c = pd.concat([infos_nb,infos_pct], sort=False)\n",
    "    # nbe de lignes total\n",
    "    infos_c[\"col_tot\"] = [infos_c.T['nb'].sum(), infos_c.T['pct'].sum()]\n",
    "    \n",
    "    infos = pd.concat([infos_l,infos_c], axis=1, sort=False)\n",
    "    \n",
    "    return infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FONCTION DE COMPTAGE DES VALEURS NULLES\n",
    "def evalNull (inf_df):\n",
    "    a = inf_df.T['null'].sum()\n",
    "    b = inf_df.T['count'].sum()\n",
    "    print(\"Nbe valeurs 'null' : {:.0f}\".format(a))\n",
    "    print(\"Nbe valeurs non 'null' : {:.0f}\".format(b))\n",
    "    print(\"Nbe total cases : {:.0f}\".format(a+b))\n",
    "    print(\"% total valeurs 'null' : {:.1f}%\".format(a*100/(a+b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui trouve les éléments uniques différents dans deux tableaux\n",
    "def Diff(tab1, tab2): \n",
    "    #tab_dif = [i for i in tab1 + tab2 if i not in tab1 or i not in tab2] # renvoie en vrac toutes les entrées spécifiques\n",
    "    return (set(tab1)-set(tab2),set(tab2)-set(tab1)) # renvoie deux tableaux spécifiques à tab1 puis tab2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction vérifiant l'unicité des lignes d'une liste de listes\n",
    "def uniCle (t_tab): \n",
    "    if isinstance(t_tab[0], type(str)) :\n",
    "        uni = list(set(t_tab))\n",
    "        res = True if (len(uni)==len(t_tab)) else False\n",
    "    else :\n",
    "        uni = list(set(zip(*t_tab))) # liste des combinaisons uniques\n",
    "        res = True if (len(uni)==len(t_tab[0])) else False\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction comparant la correspondance unique entre les valeurs d'une même ligne de deux colonnes d'une base\n",
    "# (bijection entre les valeurs de col1 et de col2)\n",
    "def Adeq (df, nom_col1,nom_col2):\n",
    "    mon_zip = zip(df[nom_col1], df[nom_col2]) # associe les entrées des deux colonnes en tuples\n",
    "    nbe_comb = len(set(mon_zip)) # retourne les valeurs uniques des tuples\n",
    "    return nbe_comb==df[nom_col1].unique().size # si le nbe est le même que les valeurs uniques, c'est bon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contAny (cars, mot):\n",
    "    return any([True if c in cars else False for c in mot])\n",
    "\n",
    "def contAll (cars, mot):\n",
    "    return all([True if c in cars else False for c in mot])\n",
    "\n",
    "def enum_mots_cmpt(li_phrases, nb): # prend une liste de phrases en entrée\n",
    "    li_mots = \" \".join(li_phrases).split(\" \")\n",
    "    li_mots_net = sorted([mot for mot in li_mots if (mot != '') \\\n",
    "                          and not contAll('-)%.(,', mot)])\n",
    "    cpt = Counter(li_mots_net)\n",
    "    words_occ = cpt.most_common(nb) # tableau de tuples\n",
    "    words = [words_occ[i][0] for i in range(len(words_occ))]  \n",
    "    occs = [words_occ[i][1] for i in range(len(words_occ))]\n",
    "    dic_occs = dict() \n",
    "    for i in range(len(words_occ)):\n",
    "        dic_occs[words[i]]=occs[i]\n",
    "    return dic_occs # dictionnaire\n",
    "\n",
    "def filt_dict(dic_t, li_pop):\n",
    "    dic = dic_t\n",
    "    [dic.pop(w) for w in li_pop if w in dic_t.keys()]\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_color_func(word=None, font_size=None, position=None, orientation=None, font_path=None, random_state=None):\n",
    "    h = int(360.0 * tone / 255.0)\n",
    "    s = int(100.0 * 255.0 / 255.0)\n",
    "    l = int(100.0 * float(np.random.randint(70, 120) / 255.0))\n",
    "    return \"hsl({}, {}%, {}%)\".format(h, s, l)\n",
    "tone = 10.0 # define the color of the words\n",
    "\n",
    "def nuageMots(dic_occs): # prend un dictionnaire {\"mot\" : nbe occurences}\n",
    "    fig = plt.figure(figsize=(18,8))\n",
    "    wordcloud = WordCloud(width=1000,height=200, background_color='black', max_words=1628,\\\n",
    "                      relative_scaling=1, color_func = None, normalize_plurals=False)\n",
    "    wordcloud.generate_from_frequencies(dic_occs)\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def histMots(dic_occs): # prend un dictionnaire {\"mot\" : nbe occurences}\n",
    "    fig = plt.figure(figsize=(18,4))\n",
    "    tab_occs = np.array([[k,int(v)] for k,v in dic_occs.items()]).T   # dictionnaire en tableau\n",
    "    x = tab_occs[0]\n",
    "    y = tab_occs[1].astype(int)\n",
    "    x_label = tab_occs[0]\n",
    "    ax = plt.bar(x, y, align = 'center', color='b')\n",
    "    plt.xticks(x, x_label, rotation=85, fontsize = 15)\n",
    "    plt.yticks(fontsize = 15)\n",
    "    plt.ylabel(\"Nb. of occurences\", fontsize = 18, labelpad = 10)\n",
    "    plt.title(\"Fréquence des mots-clés\",color='k',fontsize = 18, fontweight = 'bold')\n",
    "    plt.show() # affiche l'histogramme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FONCTION D'AFFICHAGE\n",
    "def basic_plot(plot_type, my_plot, my_x, my_y, my_x_t, xlab, ylab, my_tit, num_col):\n",
    "    if plot_type == \"plot\" :\n",
    "        my_plot.plot(my_x, my_y, '-o', color = colors[num_col])\n",
    "    elif plot_type == \"bar\" :\n",
    "        my_plot.bar(my_x, my_y, color = colors[num_col])\n",
    "    else :\n",
    "        print(\"erreur type de graphe\")\n",
    "    my_plot.set_xlabel(xlab, fontsize = 14)\n",
    "    my_plot.set_ylabel(ylab, fontsize = 14)\n",
    "    plt.xticks(my_x_t, my_x_t, rotation=85 , fontsize = 14)\n",
    "    plt.yticks(fontsize = 14)\n",
    "    plt.ylim(round(min(my_y)*0.9), round(max(my_y)*1.1)) \n",
    "    my_plot.set_title(my_tit, fontsize = 18, fontweight = 'bold')\n",
    "    plt.grid(color='grey', linestyle='dotted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'ensemble des données téléchargées se compose de 5 fichiers .csv et d'un fichier excel comportant 5 onglets.\n",
    "Il semble que l'intégralité des données des fichiers .csv soit reprise dans chacun des onglets du fichier Excel.\n",
    "\n",
    "Dans ce notebook, on appellera \"base de donnée\" l'ensemble des données, et \"table\" chacun des onglets ou fichier .csv correspondant.\n",
    "\n",
    "On travaillera sur les cinq dataframes créées dans la cellule suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisé la fonction dropna (colonne nulle) pour éliminer les colonnes fantômes \"Unamed en fin de tableau\"\n",
    "data = pd.read_csv(\"../DONNEES/EdStatsData.csv\").dropna(how='all', axis='columns')\n",
    "country = pd.read_csv(\"../DONNEES/EdStatsCountry.csv\").dropna(how='all', axis='columns')\n",
    "cnt_ser = pd.read_csv(\"../DONNEES/EdStatsCountry-Series.csv\").dropna(how='all', axis='columns')\n",
    "series = pd.read_csv(\"../DONNEES/EdStatsSeries.csv\").dropna(how='all', axis='columns')\n",
    "footnote = pd.read_csv(\"../DONNEES/EdStatsFootNote.csv\").dropna(how='all', axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Vérification et rectification de la qualité des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée 5 nouvelles dataframes \"data_c\", \"country_c\", \"series_c\", \"cnt_ser_c\" et \"footnote_c\" qui contiendront les données rectifiées :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on crée d'autres dataframes à modifier (deep copies)\n",
    "data_c = data.copy()\n",
    "country_c = country.copy()\n",
    "series_c = series.copy()\n",
    "cnt_ser_c = cnt_ser.copy()\n",
    "footnote_c = footnote.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Description globale des tables\n",
    "#### Comptage des 'null' par lignes et par colonnes pour toutes les  tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COMPTAGE DES 'NULL' par LIGNES et par COLONNES (toutes les tables)\n",
    "infos_t = pd.concat([infos(data), infos(country), infos(series),\\\n",
    "                  infos(cnt_ser), infos(footnote)], axis = 0,\\\n",
    "                 keys=['data', 'country', 'series', 'cnt_ser', 'footnote'])\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "infos_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Table \"Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_data = desc_bis(data).append(data.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalNull(inf_data)\n",
    "inf_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table \"Country\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_country = desc_bis(country).append(country.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalNull(inf_country)\n",
    "inf_country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table \"Series\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_series = desc_bis(series).append(series.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalNull(inf_series)\n",
    "inf_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table \"CountrySeries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_cnt_ser = desc_bis(cnt_ser).append(cnt_ser.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalNull(inf_cnt_ser)\n",
    "inf_cnt_ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table \"FootNote\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_footnote = desc_bis(footnote).append(footnote.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalNull(inf_footnote)\n",
    "inf_footnote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----------------- Bilan description globale ------------- \n",
    "1. La table \"Data\" est composée de 886930 lignes qui correspondent à toutes les combinaisons des entrées uniques des colonnes \"Country Code\" et \"Indicator Code\" (respectivement 242 et 3665 entrées uniques). On trouve dans chaque ligne correspondant à un couple Indicateur/Pays la valeur d'un indicateur pour un pays. Les colonnes détaillent les valeurs pour chaque année de 1970 à 2017 (48 colonnes), puis des projections de ces valeurs tous les 5 ans des années 2020 à 2100 (17 colonnes) \n",
    "2. La table \"Country\" est composée de 241 lignes correspondant aux pays sur lesquels portent les données. (Il manque un pays, voir plus bas). Chaque colonne donne des renseignements sur les pays.\n",
    "3. La table \"Series\" est composée de 3665 lignes correspondant chacune à un indicateur statistique.\n",
    "4. La table \"Country-series\" comporte 613 lignes donne des indications sur les sources des données de divers couples Indicateur/Pays.\n",
    "5. La table \"FootNote\" comporte 643638 lignes, et donne des précisions (mode de calcul ou autre) relatives à divers couples Indicateur/Pays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'analyse de la composition des tables a permis de déduire le MPD (Modèle Physique de Données) de la base représenté ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"../UML/EduStatsMPD.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les clés proposées dans le MPD ci-dessus pour chaque jeu faciliteraient l'utilisation de la base, sous réserve de quelques modifications (voir modifications plus bas) :\n",
    "- renommer certaines colonnes afin de lever les ambiguïtés\n",
    "(ex : Series/\"Series Code\" -> Series/\"Indicator Code\")\n",
    "- supprimer les colonnes redondantes ou inutiles\n",
    "(ex : Data/\"Country Name\", accessibles via la clé étrangère \"Country Code\" en colonne Country/\"Table Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Données dupliquées ou contradictoires\n",
    "\n",
    "#### Vérification de l'unicité des clés de chaque table\n",
    "\n",
    "La description ci-dessus nous a permis de déterminer les colonnes de chaque bases susceptibles de jouer le rôle de clés. Afin de faciliter l'exploitation de la base, il est important que la clé de chaque table soit unique.\n",
    "Vérifions donc que les tables sont exemptes de doublons :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Table Data : Unicité de la clé ('Country Code'&'Indicator Code') {}\"\\\n",
    "      .format(uniCle([data[\"Country Code\"], data[\"Indicator Code\"]])))\n",
    "print(\"Table Country : Unicité de la clé ('Country Code') {}\"\\\n",
    "      .format(uniCle(country[\"Country Code\"])))\n",
    "print(\"Table Series : Unicité de la clé ('Series Code') {}\"\\\n",
    "      .format(uniCle(series[\"Series Code\"])))\n",
    "print(\"Table Country-Series : Unicité de la clé ('CountryCode'&'SeriesCode') {}\"\\\n",
    "      .format(uniCle([cnt_ser[\"CountryCode\"], cnt_ser[\"SeriesCode\"]])))\n",
    "print(\"Table FootNote : Unicité de la clé ('CountryCode'&'SeriesCode'&'Year') {}\"\\\n",
    "      .format(uniCle([footnote[\"CountryCode\"],footnote[\"SeriesCode\"],footnote[\"Year\"]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les tables sont bien exemptes de doublons. Pour plus de clarté, on renomme les colonnes contenant des entrées apparentées :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_c.rename(columns={'Table Name':'Country Name'}, inplace=True)\n",
    "series_c.rename(columns={'Series Code':'Indicator Code'}, inplace=True)\n",
    "cnt_ser_c.rename(columns={'CountryCode':'Country Code',\n",
    "                          'SeriesCode':'Indicator Code',\n",
    "                         'DESCRIPTION':'Desc Data'}, inplace=True)\n",
    "footnote_c.rename(columns={'CountryCode':'Country Code',\n",
    "                          'SeriesCode':'Indicator Code',\n",
    "                         'DESCRIPTION':'Footnote Data'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correspondance des entrées uniques des colonnes apparentées\n",
    "\n",
    "- Les tables \"Data\" et \"Country\" n'ont pas le même nombre d'entrée uniques pour la colonne \"Country Code\" (voir dataframes inf_data et inf_country) : la table \"Country\" contient un pays en moins. On cherche à déterminer ce pays :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_lack = Diff(list(data[\"Country Code\"].unique()),list(country[\"Country Code\"].unique()))\n",
    "print(\"Codes des pays spécifiques à 'Data' : {}\"\\\n",
    "  .format(cnt_lack[0]))\n",
    "print(\"Codes des pays spécifiques à 'Country' : {}\"\\\n",
    "  .format(cnt_lack[1]))\n",
    "code = list(cnt_lack[0])[0]\n",
    "nom = list(data[data[\"Country Code\"]==(list(cnt_lack[0])[0])][\"Country Name\"].unique())[0]\n",
    "print(\"Code et nom du pays à ajouter : {},{}\".format(code, nom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La table Country étant supposée renseigner sur tous les pays présents dans la base, on rajoute une ligne dans la base \"Country\" contenant le pays manquant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_vgb = pd.DataFrame([[code]+[None]+[nom]+[None]*(country_c.columns.size-3)],\\\n",
    "                        columns = country_c.columns) # ligne à ajouer\n",
    "country_c = country_c.append(line_vgb,'sort=False') # ajout en bas de la liste\n",
    "country_c = country_c.sort_values(\"Country Code\") # remet les lignes en ordre alphabétique de pays\n",
    "country_c.index = list(np.arange(country_c.index.size)) # renumérote l'index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country_c.drop_duplicates(subset='Country Name', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Les entrées uniques des colonnes \"Country Name\" et \"Table Name\" des tables \"Data\" et \"Country\" ne correspondent pas :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_lack = Diff(list(data_c[\"Country Name\"].unique()),list(country_c[\"Country Name\"].unique()))\n",
    "\n",
    "print(\"* Noms des pays spécifiques à 'Data' : {}\"\\\n",
    "  .format(sorted(cnt_lack[0])))\n",
    "print(\"----------------\")\n",
    "print(\"* Noms des pays spécifiques à 'Country' : {}\"\\\n",
    "  .format(sorted(cnt_lack[1])))\n",
    "print(\"----------------\")\n",
    "print(\"* Nombre de pays non concordants : {}, {}\".format(len(cnt_lack[0]), len(cnt_lack[1])))\n",
    "# liste complète des codes des pays posant problème (data, puis country) :\n",
    "l_data = sorted([data_c[data_c[\"Country Name\"]==nom_col].iloc[0][\"Country Code\"] for nom_col in cnt_lack[0]])\n",
    "l_country = sorted([country_c[country_c[\"Country Name\"]==nom_col].iloc[0][\"Country Code\"] for nom_col in cnt_lack[1]])\n",
    "l_pbe = sorted(list(set(l_data + l_country)))\n",
    "print(\"----------------\")\n",
    "print(\"* Liste des codes des {} pays posant problème : {}\".format(len(l_pbe), l_pbe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tableau comparatif des noms de pays 'posant problème' et ayant le même code dans data et country\n",
    "mask1 = [li.any() for li in np.array([np.array((data[\"Country Code\"]==n).values) for n in l_pbe]).T]\n",
    "mask2 = [li.any() for li in np.array([np.array((country[\"Country Code\"]==n).values) for n in l_pbe]).T]\n",
    "comp = pd.merge(data[mask1], country[mask2], left_on= \"Country Code\", right_on= \"Country Code\")\n",
    "tab_ser = [comp[comp[\"Country Code\"] == pays].iloc[0][['Country Code','Country Name', 'Table Name']] \\\n",
    "           for pays in l_pbe]\n",
    "my_df = pd.DataFrame(tab_ser, columns = ['Country Code','Country Name', 'Table Name'])\n",
    "my_df.columns = ['Country Code','Country Name (data_c)', 'Country Name (country_c)' ]\n",
    "my_df.sort_values(by = ['Country Name (country_c)'], ascending = True, inplace = True)\n",
    "my_df = my_df.reset_index(drop=True)\n",
    "my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On conserve les noms de la table 'Data', qui ne contiennent pas de caractères spéciaux, et qui sont plus clairs sur la désignation ('excluding high income' préférable à 'all income levels') :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_c[\"Country Name\"].replace(to_replace = my_df['Country Name (country_c)'].values, \\\n",
    "                       value = my_df['Country Name (data_c)'].values, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Les tables \"Data\" et \"Series\" ont bien le même nombre d'entrée uniques pour la colonne \"Indicator Code\" et \"Series Code\" (voir dataframes inf_data et inf_country) : 3665. Vérifions si ces entrées uniques sont bien les mêmes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "serie_lack = Diff(list(data_c[\"Indicator Code\"].unique()),list(series_c[\"Indicator Code\"].unique()))\n",
    "\n",
    "print(\"Nbe d'indicateurs spécifiques à 'Data' : {}\"\\\n",
    "  .format(len(serie_lack[0])))\n",
    "print(\"Nbe d'indicateurs spécifiques à 'Series' : {}\"\\\n",
    "  .format(len(serie_lack[1])))\n",
    "print(\"Quelques indicateurs spécifiques à 'Data' :\\n {}\"\\\n",
    "  .format(sorted(serie_lack[0])[:5]))\n",
    "print(\"Quelques indicateurs spécifiques à 'Series' :\\n {}\"\\\n",
    "  .format(sorted(serie_lack[1])[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'échantillon d'indicateurs affichés ci-dessus ne diffèrent en fait que par 1) des espaces 2) des lettres en minuscule dans la table \"Series\". Vérifions qu'après correction les entrées sont les mêmes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ser = pd.Series([series[\"Series Code\"][i].upper().replace(\" \", \"\")\\\n",
    "                for i in range(series[\"Series Code\"].index.size)],\\\n",
    "                 index = series[\"Series Code\"].index)\n",
    "test_data = pd.Series([data[\"Indicator Code\"][i].upper().replace(\" \", \"\")\\\n",
    "                for i in range(data[\"Indicator Code\"].index.size)],\\\n",
    "                 index = data[\"Indicator Code\"].index)\n",
    "lack1 = Diff(list(data[\"Indicator Code\"].unique()),list(test_ser.unique()))\n",
    "lack2 = Diff(list(test_data.unique()), list(series[\"Series Code\"].unique()))\n",
    "lack3 = Diff(list(test_data.unique()), list(test_ser.unique()))\n",
    "\n",
    "print(\"-----Correction de 'Series' seule :-----\")\n",
    "print(\"Nbe d'indicateurs spécifiques à 'Data', puis 'Series' : {}, {}\"\\\n",
    "  .format(len(lack1[0]), len(lack1[1])))\n",
    "print(\"-----Correction de 'Data' seule :-----\")\n",
    "print(\"Nbe d'indicateurs spécifiques à 'Data', puis 'Series' : {}, {}\"\\\n",
    "  .format(len(lack2[0]), len(lack2[1])))\n",
    "print(\"-----Correction de 'Data' et 'Series' :-----\")\n",
    "print(\"Nbe d'indicateurs spécifiques à 'Data', puis 'Series' : {}, {}\"\\\n",
    "  .format(len(lack3[0]), len(lack3[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La correction des noms des deux bases est nécessaire. On effectue la correction des indicateurs dans la base 'Data', dans la base 'Series'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_c[\"Indicator Code\"].replace(to_replace = serie_lack[0], \\\n",
    "                        value = [x.upper().replace(\" \", \"\") for x in serie_lack[0]], inplace=True)\n",
    "series_c[\"Indicator Code\"].replace(to_replace = serie_lack[1], \\\n",
    "                             value =[x.upper().replace(\" \", \"\") for x in serie_lack[1]], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_lack2 = Diff(list(data_c[\"Indicator Code\"].unique()),list(series_c[\"Indicator Code\"].unique()))\n",
    "print(\"Nbe d'indicateurs spécifiques à 'Data' et à 'Series' après modification : {}, {}\"\\\n",
    "      .format(len(serie_lack2[0]),len(serie_lack2[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vérifions que les codes d'indicateurs et de pays présents dans les tables \"Country-Series\" et \"Footnote\" sont bien dans la liste des codes d'indicateurs de la table \"Series\" et dans la liste des codes de pays de la table \"Country\" :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_ser_lack1 = Diff(list(series_c[\"Indicator Code\"].unique()),list(cnt_ser_c[\"Indicator Code\"].unique()))\n",
    "cnt_ser_lack2 = Diff(list(country_c[\"Country Code\"].unique()),list(cnt_ser_c[\"Country Code\"].unique()))\n",
    "footnote_lack1 = Diff(list(series_c[\"Indicator Code\"].unique()),list(footnote_c[\"Indicator Code\"].unique()))\n",
    "footnote_lack2 = Diff(list(country_c[\"Country Code\"].unique()),list(footnote_c[\"Country Code\"].unique()))\n",
    "\n",
    "print(\"-------- table 'CountrySeries' --------\")\n",
    "print(\"Nbe d'indicateurs/de pays spécifiques à 'Series'/'Country' : {}/{}\"\\\n",
    "  .format(len(cnt_ser_lack1[0]), len(cnt_ser_lack2[0])))\n",
    "print(\"Nbe d'indicateurs/de pays spécifiques à 'CountrySeries' : {}/{}\"\\\n",
    "  .format(len(cnt_ser_lack1[1]), len(cnt_ser_lack2[1])))\n",
    "print(\"-------- table 'FootNote' --------\")\n",
    "print(\"Nbe d'indicateurs/de pays spécifiques à 'Series'/'Country' : {}/{}\"\\\n",
    "  .format(len(footnote_lack1[0]), len(footnote_lack2[0])))\n",
    "print(\"Nbe d'indicateurs/de pays spécifiques à 'FootNote' : {}/{}\"\\\n",
    "  .format(len(footnote_lack1[1]), len(footnote_lack2[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base 'CountrySeries' ne contient ni de code de pays ni de code d'indicateur qui ne soit pas dans les bases 'Country' et 'Series', en revanche, la base 'FootNote' contient des codes d'indicateurs erronnés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-------------\")\n",
    "# pays pas dans footnote, \n",
    "#print(\"Quelques code pays seulement dans footnote :\\n{}\".format(list(footnote_lack2[0])[:15]))\n",
    "\n",
    "#pays seulement dans footnote\n",
    "print(\"Quelques code pays seulement dans footnote :\\n{}\".format(list(footnote_lack2[1])[:5]))\n",
    "\n",
    "print(\"-------------\")\n",
    "# codes indicateurs pas dans footnote,\n",
    "#print(\"Quelques indicateurs de 'series' pas dans 'footnote' :\\n{}\".format(list(footnote_lack1[0])[:3]))\n",
    "\n",
    "#codes indicateurs seulement dans footnote\n",
    "print(\"Quelques indicateurs seulement dans 'footnote' :\\n{}\".format(list(footnote_lack1[1])[:25]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les codes d'indicateurs de 'FootNote' contiennent des lettres en minuscules. On applique la même modification que pour les tables 'Data' et 'Series' précédemment (élimination des espaces, passage en majuscules). On vérifie qu'après correction 'FootNote' n'a pas de codes d'indicateurs spécifiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "footnote_c[\"Indicator Code\"].replace(to_replace = footnote_lack1[1], \\\n",
    "                        value = [x.upper().replace(\" \", \"\") for x in footnote_lack1[1]], inplace=True)\n",
    "footnote_lack = Diff(list(footnote_c[\"Indicator Code\"].unique()),list(series_c[\"Indicator Code\"].unique()))\n",
    "print(\"Nbe d'indicateurs spécifiques à 'Data' et à 'Series' après modification : {}, {}\"\\\n",
    "      .format(len(footnote_lack[0]),len(footnote_lack[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Y a-t-il une correspondance entre les noms d'indicateurs de la table \"Series\" et ceux de la table \"Data\" ? Si oui, comme pour les noms de pays, on ne gardera qu'une des deux colonnes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que 462 entrées uniques de la colonne \"Indicator Name\" de la table \"data\" ne sont pas dans la table \"series\" et que le même nombre 462 d'entrées uniques de la même colonne de la table \"series\" ne sont pas dans la table \"data\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indic_lack = Diff(list(data_c[\"Indicator Name\"].unique()),list(series[\"Indicator Name\"].unique()))\n",
    "#noms d'indicateurs seulement dans data\n",
    "print(\"Quelques indicateurs seulement dans 'Data' :\\n{}\".format(list(indic_lack[0])[:3]))\n",
    "#noms d'indicateurs seulement dans series\n",
    "print(\"Quelques indicateurs seulement dans 'Series' :\\n{}\".format(list(indic_lack[1])[:3]))\n",
    "print(\"----------------\")\n",
    "print(\"* Nombre de pays non concordants : {}, {}\".format(len(indic_lack[0]), len(indic_lack[1])))\n",
    "# liste complète des codes des indicateurs posant problème (data, puis series) :\n",
    "l_data = sorted([data_c[data_c[\"Indicator Name\"]==nom_col].iloc[0][\"Indicator Code\"] for nom_col in indic_lack[0]])\n",
    "l_series = sorted([series_c[series_c[\"Indicator Name\"]==nom_col].iloc[0][\"Indicator Code\"] for nom_col in indic_lack[1]])\n",
    "l_pbe = sorted(list(set(l_data + l_series)))\n",
    "print(\"----------------\")\n",
    "print(\"* Liste des codes de quelques-uns des {} pays posant problème : {}\".format(len(l_pbe), l_pbe[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tableau comparatif des noms de pays 'posant problème' et ayant le même code dans data et series\n",
    "mask1 = [li.any() for li in np.array([np.array((data_c[\"Indicator Code\"]==n).values) for n in l_pbe]).T]\n",
    "mask2 = [li.any() for li in np.array([np.array((series_c[\"Indicator Code\"]==n).values) for n in l_pbe]).T]\n",
    "comp = pd.merge(data_c[mask1], series_c[mask2], left_on= \"Indicator Code\", right_on= \"Indicator Code\")\n",
    "tab_ser = [comp[comp[\"Indicator Code\"] == ind].iloc[0][['Indicator Code','Indicator Name_x', 'Indicator Name_y']] \\\n",
    "           for ind in l_pbe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des noms complets\n",
    "# comp[['Indicator Code','Indicator Name_x', 'Indicator Name_y', 'Country Name']]\\\n",
    "# .groupby(['Indicator Code','Indicator Name_x','Indicator Name_y']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame(tab_ser, columns = ['Indicator Code','Indicator Name_x', 'Indicator Name_y'])\n",
    "my_df.columns = ['Indicator Code','Indicator Name (data_c)', 'Indicator Name (series_c)' ]\n",
    "my_df.sort_values(by = ['Indicator Name (series_c)'], ascending = True, inplace = True)\n",
    "#my_df = my_df.reset_index(drop=True)\n",
    "my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les noms de la table 'Series' sont généralement plus complets que ceux de 'Data'. On remplace donc les valeurs de 'Indicator Name' dans 'data_c' par celles de la même colonne dans 'series_c' : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# A FAIRE  #########################\n",
    "# Remplacement par le nom le plus long des deux\n",
    "# Vérifier quand même que des indicateurs plus courts n'ont pas été remplacés par des plus longs !!!!\n",
    "#################################################\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remplacement des noms de la colonne data, par ceux de la colonne series\n",
    "data_c[\"Indicator Name\"].replace(to_replace = my_df['Indicator Name (data_c)'].values, \\\n",
    "                        value = my_df['Indicator Name (series_c)'].values, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vérification de la correspondance après modification\n",
    "verif = Diff(sorted(data_c[\"Indicator Name\"].unique()), sorted(series_c[\"Indicator Name\"].unique()))\n",
    "list(verif[0])[:5], list(verif[1])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_c[\"Indicator Name\"].unique()), len(series_c[\"Indicator Name\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simplification de la base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# A FAIRE  #########################\n",
    "# Fusion des tables footnote_c et cnt_ser_c en une table inf_data_c\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Les années de la table \"FootNote\" sont apparemment dans un format string et précédés de YR ou yr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste des années de la colonne \"Year\" de la table \"FootNote\"\n",
    "print(set(footnote_c[\"Year\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remplace les valeurs des chaînes par l'entier correspondant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remplacement des années de la colonne 'Year', par les nombres correspondants\n",
    "ch_ann_uni = list(footnote_c[\"Year\"].unique())\n",
    "int_ann_uni = [int(('').join(re.findall(\"[0-9]\", chaine))) for chaine in ch_ann_uni]\n",
    "footnote_c[\"Year\"].replace(to_replace = ch_ann_uni, value = int_ann_uni, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(footnote_c[\"Year\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relations bijectives entre colonnes d'une même base\n",
    "\n",
    "Après vérification de l'unicité des clés choisies pour chaque table, on vérifie la correspondance bijective entre plusieurs paires de colonnes d'une même table, par exemple :\n",
    " - les codes de pays et les noms de pays (dans 'Data' et dans 'Country')\n",
    " - les codes d'indicateurs et les noms d'indicateurs (dans 'Data' et dans 'Series')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On teste (voir définition de la fonction 'Adeq' plus haut) les couples de colonnes listés ci-dessous :\n",
    "- Table \"Data\" : \"Country Code\", \"Country Name\" ( Dataframe \"data_c\" : \"Country Code\", \"Country Name\" )\n",
    "- Table \"Data\" : \"Indicator Code\", \"Indicator Name\" ( Dataframe \"data_c\" : \"Indicator Code\", \"Indicator Name\" )\n",
    "- Table \"Country\" : \"Country Code\", \"Short Name\" ( Dataframe \"country_c\" : \"Country Code\", \"Short Name\" )\n",
    "- Table \"Country\" : \"Country Code\", \"Table Name\" ( Dataframe \"country_c\" : \"Country Code\", \"Country Name\" )\n",
    "- Table \"Country\" : \"Country Code\", \"Long Name\" ( Dataframe \"country_c\" : \"Country Code\", \"Long Name\" )\n",
    "- Table \"Series\" : \"Series Code\", \"Indicator Name\" ( Dataframe \"series_c\" : \"Indicator Code\", \"Indicator Name\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data : {} {}\"\\\n",
    "      .format(Adeq(data_c, \"Country Code\", \"Country Name\"), Adeq(data_c, \"Indicator Code\", \"Indicator Name\")))\n",
    "print(\"Country : {} {} {}\"\\\n",
    "      .format(Adeq(country_c, \"Country Code\", \"Short Name\"), Adeq(country_c, \"Country Code\", \"Country Name\"),\\\n",
    "        Adeq(country_c, \"Country Code\", \"Long Name\")))\n",
    "print(\"Series : {}\".format(Adeq(series_c, \"Indicator Code\", \"Indicator Name\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Données manquantes\n",
    "#### Comptage des données manquantes par table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (18,3))\n",
    "\n",
    "colors = [\"#bd5db0\",\"#70a845\",\"#727bcc\",\"#b49242\",\"#cc566c\",\"#4aad92\",\"#ca6037\"]\n",
    "\n",
    "x=inf_data.columns[4:]\n",
    "xlab=[my_str[:11]+\"...\" if len(my_str)>11 else my_str for my_str in x]\n",
    "y1=inf_data[inf_data.columns[4:]].loc[\"null\"]*100/data_c.shape[0] # % de valeurs nulles\n",
    "y2=inf_data[inf_data.columns[4:]].loc[\"count\"] # nombre de valeurs\n",
    "\n",
    "plot1 = plt.subplot(1,2,1)\n",
    "basic_plot(\"bar\", plot1, xlab, y1, xlab[::4], \"\", \"% NaN\",  \"% Données manquantes\\n(Data)\", 0)\n",
    "\n",
    "plot2 = plt.subplot(1,2,2)\n",
    "basic_plot(\"bar\", plot2, xlab, y2, xlab[::4], \"\", \"Nbe non nul\",  \"Nbe d'entrées\\n(Data)\", 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nbe de remplissage minimum/maximum et année correspondante\n",
    "sel_data = inf_data.loc[\"count\"][4:]\n",
    "val_min = sel_data.min()\n",
    "val_max = sel_data.max()\n",
    "\n",
    "print(\"- année nbe entrées min, nbe entrées min : \\n{}, \\n{:.0f}, soit {:.3f}%\"\\\n",
    "      .format(sel_data.index[sel_data==val_min], \\\n",
    "              val_min, val_min*100/(data.shape[0])))\n",
    "\n",
    "print(\"- année nbe entrées max, nbe entrées max : \\n{}, \\n{:.0f}, soit {:.3f}%\"\\\n",
    "     .format(sel_data.index[sel_data==val_max], \\\n",
    "             val_max, val_max*100/(data.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La table \"Data\" donnant la valeur d'un indicateur pour une année comporte environ 86 % de données non renseignées.\n",
    "- Environ 60% de l'ensemble des couples Indicateur/Pays n'a aucune valeur renseignée.\n",
    "- L'année la mieux renseignée est l'année 2010 (27% des couples Indicateur/Pays, soit plus de 242 000 valeurs), et les moins renseignées sont les années 2016 et 2017 (respectivement 1,8% et 0,016% des couples, soit 16460 et 143 valeurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (18,3))\n",
    "\n",
    "x=inf_country.columns\n",
    "xlab=[my_str[:11]+\"...\" if len(my_str)>11 else my_str for my_str in x]\n",
    "y1=inf_country.loc[\"null\"]*100/country.shape[0]  # % de valeurs nulles\n",
    "y2=inf_country.loc[\"count\"] # nombre de valeurs\n",
    "\n",
    "plot1 = plt.subplot(1,2,1)\n",
    "basic_plot(\"bar\", plot1, xlab, y1, xlab, \"\", \"% NaN\",  \"% Données manquantes\\n(Country)\", 0)\n",
    "\n",
    "plot2 = plt.subplot(1,2,2)\n",
    "basic_plot(\"bar\", plot2, xlab, y2, xlab, \"\", \"Nbe non nul\",  \"Nbe d'entrées\\n(Country)\", 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (18,3))\n",
    "\n",
    "x=inf_series.columns\n",
    "xlab=[my_str[:11]+\"...\" if len(my_str)>11 else my_str for my_str in x]\n",
    "y1=inf_series.loc[\"null\"]*100/series.shape[0]  # % de valeurs nulles\n",
    "y2=inf_series.loc[\"count\"] # nombre de valeurs\n",
    "\n",
    "plot1 = plt.subplot(1,2,1)\n",
    "basic_plot(\"bar\", plot1, xlab, y1, xlab, \"\", \"% NaN\",  \"% Données manquantes\\n(Series)\", 0)\n",
    "\n",
    "plot2 = plt.subplot(1,2,2)\n",
    "basic_plot(\"bar\", plot2, xlab, y2, xlab, \"\", \"Nbe non nul\",  \"Nbe d'entrées\\n(Series)\", 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"la table 'CountrySeries' contient {} entrées nulles\".format(inf_cnt_ser.loc[\"null\"].sum()))\n",
    "print(\"la table 'FootNote' contient {} entrées nulles\".format(inf_footnote.loc[\"null\"].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajout à la table 'Data'\n",
    "Pour faciliter le traitement ultérieur des données de la table \"Data\", on ajoute deux colonnes précisant :\n",
    "- la région du pays \n",
    "- et le topic de l'indicateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajout de la région du pays\n",
    "data_c = pd.merge( data_c , country_c[['Country Code', 'Region']] , left_on = 'Country Code', right_on = 'Country Code' )\n",
    "# ajout du topic de l'indicateur\n",
    "data_c = pd.merge( data_c , series_c[['Indicator Code', 'Topic']] , left_on = 'Indicator Code', right_on = 'Indicator Code' )\n",
    "cols = list(data_c.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = cols[-2:]+cols[:-2]\n",
    "data_c = data_c[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elimination des colonnes sous-remplies\n",
    "\n",
    "Il existe des colonnes dans les tables 'Country', 'Series', 'Country-Series' et 'Footnote' qui sont très peu remplies. Cependant, les données contenues dans ces tables ne sont pas indispensables au traitement des données chiffrées, qui sont contenues dans la table 'Data'. On n'éliminera donc pas ces colonnes.\n",
    "En ce qui concerne la table 'Data', elle contient seulement deux colonnes peu remplies (années 2016 et 2017) qu'il n'est pas nécessaire d'effacer pour l'instant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groupes de pays en régions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dans la liste country_c[\"Country Name\"], on remarque 27 pays n'ayant pas de valeur de country[\"Region\"] et country[\"Income group\"]. Ceux-ci sont en fait des groupes de pays. On élimine les données relatives à ces pays (data_c) de notre liste d'intérêt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comptage des pays uniques sans région\n",
    "sans_reg_cnt = country_c[country_c[\"Region\"].isna()][\"Country Name\"]\n",
    "li_pays_supp = sans_reg_cnt.values\n",
    "#['Arab World', 'East Asia & Pacific (excluding high income)','East Asia & Pacific', 'Europe & Central Asia (excluding high income)', 'Europe & Central Asia', 'Euro area', 'European Union', 'Gibraltar', 'High income', 'Heavily indebted poor countries (HIPC)', 'Latin America & Caribbean (excluding high income)', 'Latin America & Caribbean', 'Least developed countries: UN classification', 'Low income', 'Lower middle income', 'Low & middle income', 'Middle East & North Africa', 'Middle income', 'Middle East & North Africa (excluding high income)', 'North America', 'Nauru', 'OECD members', 'South Asia', 'Sub-Saharan Africa (excluding high income)', 'Sub-Saharan Africa', 'Upper middle income', 'British Virgin Islands', 'World']\n",
    "print(Diff(sans_reg_cnt, sans_reg_cnt) , len(sans_reg_cnt))\n",
    "print(li_pays_supp) # faux 'pays' à éliminer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# élimination des faux 'pays' dans \"Country\"\n",
    "ind_supp_cnt = sans_reg_cnt.index # index des lignes du tableau country à éliminer (une seule par nom)\n",
    "country_c.drop(index = ind_supp_cnt, inplace = True)\n",
    "# élimination des faux 'pays' dans \"Data\"\n",
    "sans_reg_data = [data_c[data_c[\"Country Name\"]== col].index for col in li_pays_supp] # liste de listes d'index à retirer\n",
    "ind_supp_data = [item for sublist in sans_reg_data for item in sublist] # liste des index (applatie)\n",
    "data_c.drop(index = ind_supp_data, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vérification\n",
    "sans_reg_cnt = country_c[country_c[\"Region\"].isna()][\"Country Name\"]\n",
    "len(sans_reg_cnt)\n",
    "sans_reg_cnt = country_c[country_c[\"Region\"].isna()][\"Country Name\"]\n",
    "sans_reg_data = data_c[data_c[\"Region\"].isna()][\"Country Name\"]\n",
    "print(len(sans_reg_cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nombre de régions et de pays par régions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (30,3))\n",
    "\n",
    "x=tab[:50].index\n",
    "xlab=[my_str[:8]+\"...\" if len(my_str)>8 else my_str for my_str in x]\n",
    "y=tab[:50]\n",
    "\n",
    "plot1 = plt.subplot(1,2,1)\n",
    "basic_plot(\"bar\", plot1, xlab, y, xlab, \"\", \"% NaN\",  \"% Données manquantes\\n(Series)\", 0)\n",
    "\n",
    "# plot2 = plt.subplot(1,2,2)\n",
    "# basic_plot(\"bar\", plot2, xlab, y2, xlab, \"\", \"Nbe non nul\",  \"Nbe d'entrées\\n(Series)\", 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code de pays et région associée\n",
    "\n",
    "fig = plt.figure(figsize = (15,5))\n",
    "\n",
    "df2 = country_c[['Country Name', 'Region']].groupby('Region').count()\n",
    "li_region = list(df2.index)\n",
    "x = li_region\n",
    "xlab = [my_str[:10]+\"...\" if len(my_str)>8 else my_str for my_str in x]\n",
    "y1 = df2.values.reshape(len(df2.values),)\n",
    "y2 = \n",
    "\n",
    "# Nombre de pays par région\n",
    "plot1 = plt.subplot(1,2,1)\n",
    "basic_plot(\"bar\", plot1, xlab, y1, xlab, \"\", \"Région\",  \"Nombre de pays par région\", 5)\n",
    "labels = [ '{:.0f} pays'.format(y1[i]) for i in range(len(y1))] \n",
    "for label,xlab, y1 in zip(labels, xlab, y1):\n",
    "    plt.annotate(label, xy=(xlab, y1), xytext=(-17, 3),\n",
    "        textcoords='offset points', ha='left', va='bottom' )\n",
    "plt.ylim(0,65)\n",
    "\n",
    "# Nombre d'habitants cumulés par région\n",
    "plot2 = plt.subplot(1,2,2)\n",
    "basic_plot(\"bar\", plot2, xlab, y2, xlab, \"\", \"Région\",  \"Nombre d'habitants par région\", 5)\n",
    "labels = [ '{:.0f} pays'.format(y2[i]) for i in range(len(y))] \n",
    "for label,xlab, y2 in zip(labels, xlab, y2):\n",
    "    plt.annotate(label, xy=(xlab, y2), xytext=(-17, 3),\n",
    "        textcoords='offset points', ha='left', va='bottom' )\n",
    "plt.ylim(0,65)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre d'indicateurs par pays pour chaque année\n",
    "df1 = data_c.groupby(['Country Name', 'Country Code']).count()[data_c.columns[4:]]\n",
    "# liste des codes pays et de leurs régions\n",
    "df2 = country_c[['Country Code', 'Region']]\n",
    "# Nombre d'indicateurs par région\n",
    "df3 = pd.merge(df1, df2, left_on = 'Country Code', right_on = 'Country Code')\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indicateurs sous-remplis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (30,4))\n",
    "\n",
    "# tableau du pourcentage d'indicateurs renseignés par pays ()\n",
    "gp = data_c.groupby(['Country Name']).count()\n",
    "nb_col_an = data_c[4:].shape[1]\n",
    "nb_indic = series_c['Indicator Code'].shape[0]\n",
    "nb_max = (nb_col_an*nb_indic)\n",
    "tab = gp[gp.columns[3:]].sum(axis=1)*100/nb_max\n",
    "tab.sort_values(ascending=False,inplace=True)\n",
    "\n",
    "x=tab.index\n",
    "xlab=[my_str[:8]+\"...\" if len(my_str)>8 else my_str for my_str in x]\n",
    "y=tab\n",
    "\n",
    "plot1 = plt.subplot(1,2,1)\n",
    "basic_plot(\"bar\", plot1, xlab, y, '', \"Tous les pays\", \"% indicateur renseigné\",  \"% Indicateurs renseignés sur toutes les années \\n(Data)\", 5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## idem mais avec tranches d'années\n",
    "fig = plt.figure(figsize = (30,4))\n",
    "\n",
    "# tableau du pourcentage d'indicateurs renseignés par pays ()\n",
    "gp = data_c.groupby(['Country Name']).count()\n",
    "nb_col_an = data_c[4:].shape[1]\n",
    "nb_indic = series_c['Indicator Code'].shape[0]\n",
    "nb_max = (nb_col_an*nb_indic)\n",
    "tab = gp[gp.columns[3:]].sum(axis=1)*100/nb_max\n",
    "tab.sort_values(ascending=False,inplace=True)\n",
    "\n",
    "x=tab.index\n",
    "xlab=[my_str[:8]+\"...\" if len(my_str)>8 else my_str for my_str in x]\n",
    "y=tab\n",
    "\n",
    "plot1 = plt.subplot(1,2,1)\n",
    "basic_plot(\"bar\", plot1, xlab, y, '', \"Tous les pays\", \"% indicateur renseigné\",  \"% Indicateurs renseignés sur toutes les années \\n(Data)\", 5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = data_c.groupby([['Country Name', 'Region']]).count()\n",
    "gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour la première région\n",
    "fig = plt.figure(figsize = (30,3))\n",
    "\n",
    "li_region\n",
    "\n",
    "\n",
    "# tableau du pourcentage d'indicateurs renseignés par pays ()\n",
    "gp = data_c.groupby(['Country Name']).count()\n",
    "nb_col_an = data_c[4:].shape[1]\n",
    "nb_indic = series_c['Indicator Code'].shape[0]\n",
    "nb_max = (nb_col_an*nb_indic)\n",
    "tab = gp[gp.columns[3:]].sum(axis=1)*100/nb_max\n",
    "tab.sort_values(ascending=False,inplace=True)\n",
    "\n",
    "x=tab[:500].index\n",
    "xlab=[my_str[:8]+\"...\" if len(my_str)>8 else my_str for my_str in x]\n",
    "\n",
    "#y=tab[:500]\n",
    "tab_y = \n",
    "\n",
    "plot1 = plt.subplot(1,2,1)\n",
    "basic_plot(\"bar\", plot1, xlab, y, '', \"Tous les pays\", \"% indicateur renseigné\",  \"% Indicateurs renseignés sur toutes les années \\n(Data)\", 5)\n",
    "\n",
    "# plot2 = plt.subplot(1,2,2)\n",
    "# basic_plot(\"bar\", plot2, xlab, y2, xlab, \"\", \"Nbe non nul\",  \"Nbe d'entrées\\n(Series)\", 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploration des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les indicateurs qui nous intéressent sont ceux des dernières années.\n",
    "On cherche à savoir :\n",
    "- combien d'indicateurs environ sont disponibles dans les dernières années\n",
    "- quels sont les pays qui ont le plus d'indicateurs disponibles dans les dernières années\n",
    "- quels sont les indicateurs le plus souvent disponible "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nombres d'indicateurs disponibles selon les années"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tableau des nombres d'indicateurs dispo pour chaque pays et chaque année \n",
    "nb_ind_cnt = data_c.groupby(['Country Name']).count()[data_c.columns[4:]]\n",
    "# Pays ayant un nbe d'indicateur non nul en 2017\n",
    "#nb_ind_cnt[nb_ind_cnt['2017']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nbe de pays ayant un nbe d'indicateur supérieur à n en fonction des années\n",
    "\n",
    "def calc_nb_pay_rens (tab_n):\n",
    "    tab = [ [nb_ind_cnt[nb_ind_cnt[str(i)]>j].index.size for i in years] for j in tab_n ]\n",
    "    res = np.array(tab).T\n",
    "    return res\n",
    "\n",
    "countrys = [nb_ind_cnt.index[i][0] + \" - \" + nb_ind_cnt.index[i][1] for i in range(nb_ind_cnt.index.size)]\n",
    "years = list(range(1970,2018))+list(range(2020,2105,5))\n",
    "tab_n = [0,2,10,50,100, 200, 500]\n",
    "x = years\n",
    "y = calc_nb_pay_rens(tab_n)\n",
    "len(y[:, 1]), len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (18,6))\n",
    "\n",
    "colors = [\"#bd5db0\",\"#70a845\",\"#727bcc\",\"#b49242\",\"#cc566c\",\"#4aad92\",\"#ca6037\"]\n",
    "labels = [\"i=\"+str(i) for i in tab_n]\n",
    "\n",
    "plot1 = plt.subplot(1,2,1)\n",
    "[plot1.plot(x, y[:,i], '-o', label = labels[i], color = colors[i]) for i in range(len(tab_n))]\n",
    "plot1.set_ylim(0,250)\n",
    "plot1.legend(loc = 'lower right')\n",
    "plot1.set_xlabel(\"années\", fontsize = 14)\n",
    "plot1.set_ylabel(\"nbe de pays\", fontsize = 14)\n",
    "plot1.set_title(\"Pays ayant plus de i indicateurs\", fontsize = 18, fontweight = 'bold')\n",
    "\n",
    "plot2 = plt.subplot(1,2,2)\n",
    "[plot2.plot(x, y[:,i], '-o', label = labels[i], color = colors[i]) for i in range(len(tab_n))]\n",
    "plot2.set_xlim(1980,2018)\n",
    "plot2.set_ylim(75,250)\n",
    "plot2.legend(loc = 'lower right')\n",
    "plot2.set_xlabel(\"années\", fontsize = 14)\n",
    "plot2.set_ylabel(\"nbe de pays\", fontsize = 14)\n",
    "plot2.set_title(\"Pays ayant plus de i indicateurs (zoom)\", fontsize = 18, fontweight = 'bold')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tous les pays ont au moins 1 indicateur\n",
    "- 167 pays ont des projections d'indicateurs (entre 200 et 500)\n",
    "- les données sont très rares pour l'année 2018 (7 indicateurs pour la grande majorité des pays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Heatmap du nombre d'indicateurs (pays/années)\n",
    "fig = plt.figure(figsize = (28,12))\n",
    "heat_map = sns.heatmap(nb_ind_cnt)\n",
    "#####################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration des mots clés dans les noms d'indicateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pop = [\"in\", \"of\", \"a\", \"and\", \"Per\", \"by\", \"the\", \"with\", \"to\", \"from\",\\\n",
    "            \"for\", \"who\", \"on\", \"are\"] # liste des mots non considérés\n",
    "\n",
    "# génération dictionnaire effectif mots-clés \n",
    "dic_occs = enum_mots_cmpt(data[\"Indicator Name\"], 30) # à parti des noms d'indicateurs dans \"Data\"\n",
    "dic_occs = filt_dict(dic_occs,list_pop) # filtrage des mots indésirables\n",
    "dic_occs2 = enum_mots_cmpt(data[\"Country Name\"], 30) # à partir des indicateurs uniques\n",
    "dic_occs2 = filt_dict(dic_occs,list_pop) # filtrage des mots indésirables\n",
    "\n",
    "nuageMots(dic_occs), nuageMots(dic_occs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "histMots(dic_occs), histMots(dic_occs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PBE A REGLER : les deux graphes sortent les mêmes résultats !!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Détection des outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prend un tableau de valeurs, calcule la moyenne, l'écart type\n",
    "# et renvoie les valeurs au-delà ou en-deça de x fois l'écart type\n",
    "def detOutliers(df,col,x):\n",
    "    moy = df[col].mean()\n",
    "    std = df[col].std()\n",
    "    out_val = [nb for nb in df[col].values if ((nb<moy-(x*std)) or (nb>moy+(x*std)))]\n",
    "    return df[df[col].isin(out_val)]\n",
    "\n",
    "my_tab = [1,3,0,2,5]\n",
    "df = pd.DataFrame({'my_col' : my_tab})\n",
    "\n",
    "tab_df = [detOutliers(df, \"my_col\",x) for x in np.linspace(0,2.5,7)]\n",
    "[plt.plot(df.index, df[\"my_col\"].values,'o-', label = \"x = \"+str(df.index.values)) for df in tab_df]\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### violon plot (seaborn)\n",
    "# montre la distribution également\n",
    "# éliminer les quantiles extrêmes (zscore supérieur à 3...)\n",
    "# chercher des indicateurs pertinents, valider, itérer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (plot1, plot2) = plt.subplots(1, 2, figsize = (25,6), gridspec_kw={'width_ratios': [3, 2]})\n",
    "x=[1,2,3]\n",
    "y=[8,7,6]\n",
    "# plot1.plot(x, y)\n",
    "# plot2.plot(y, x)\n",
    "\n",
    "plot1 = plt.subplot(1,2,1)\n",
    "#data.boxplot(column = list(data.columns[4:52]))\n",
    "plot1.boxplot(data_c[data_c.columns['1970':'2017']])\n",
    "#plot1.set_ylim(-300,550050)\n",
    "\n",
    "# plot2 = plt.subplot(1,2,2)\n",
    "# plot2.boxplot(data_val_0)\n",
    "# #data[data.columns[52:]].dropna(inplace = False).boxplot(data.columns[52:])\n",
    "# plot2.set_ylim(-3,20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------- BROUILLONS -------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## groupby, merge, join, concat etc.\n",
    "\n",
    "#DataFrame.merge(right, how='inner', on=None, left_on=None, right_on=None, left_index=False,\n",
    "# right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None)\n",
    "df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'], 'value': [1, 2, 3, 1], 'value2': [100, 200, 300, 500]})\n",
    "df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'], 'value': [5, 6, 7, 8]})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.merge(df2, right_on='rkey')\n",
    "df1.merge(df2, left_on = 'lkey', right_on='rkey')\n",
    "df1.groupby(['value', 'lkey']).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_gp = data.groupby(['Country Name']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_gp[my_gp.columns[3:]].sum(axis=1) # tableau du nbe total d'indicateurs valables multiannées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_gp.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = data[data[\"Indicator Code\"]=='SP.POP.1524.TO.UN']\n",
    "my_df.dropna(how = 'all', inplace = True)\n",
    "x = my_df[\"Country Name\"]\n",
    "y = my_df[\"2000\"]\n",
    "# pop de 15 à 24 ans en 2000 selon les pays :\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab1 = [4, 0,1,np.nan,50]\n",
    "tab2 = [10, 20,30,np.nan,50]\n",
    "tab3 = [np.nan, np.nan,np.nan,3,np.nan]\n",
    "df = pd.DataFrame([tab1,tab2,tab3]).rename(index={0:'coucou', 1:'recou', 2:'rerec'})\n",
    "df[\"total\"] = [10,100,1000]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En cas de noms de colonnes différents :\n",
    "df1 = pd.DataFrame({'code1': ['B', 'J', 'L', 'S'],\\\n",
    "                    'employee': ['Bob', 'Jake', 'Lisa', 'Suez'],\n",
    "                    'department': ['Accounting', 'Engineering', 'Engineering', 'HR']})\n",
    "df2 = pd.DataFrame({'code2': ['L', 'B', 'J', 'S'],\\\n",
    "                    'emp_name': ['Liça', 'Bobby', 'Jack', 'Sue'],\n",
    "                    'date': [2004, 2008, 2012, 2014]})\n",
    "\n",
    "Diff(df1[\"employee\"].unique(),df2[\"emp_name\"].unique())\n",
    "lipbe = ['B','L', 'S','J']\n",
    "mask1 = [li.any() for li in np.array([np.array((df1[\"code1\"]==n).values) for n in lipbe]).T]\n",
    "mask2 = [li.any() for li in np.array([np.array((df2[\"code2\"]==n).values) for n in lipbe]).T]\n",
    "\n",
    "# merge de 2 sélections de dataframe (noms posant problème)\n",
    "comp = pd.merge(df1[mask1], df2[mask2], left_on= \"code1\", right_on= \"code2\")\n",
    "comp[['code1','employee', 'emp_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.replace(to_replace=comp['employee'].values, value=comp['emp_name'].values, inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({'code1': ['B', 'J', 'L', 'S'],\\\n",
    "                    'employee': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    })\n",
    "df4 = pd.DataFrame({'code1': ['B', 'J', 'L', 'S'],\\\n",
    "                    'emp': ['Bob', 'Jack', 'Liza', 'Suez'],\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[\"employee\"].loc[1] = df4[\"emp\"].loc[1]\n",
    "df3[\"employee\"][df3[\"employee\"]=='Lisa']  = df4[\"emp\"].loc[df3[df3[\"employee\"]=='Lisa'].index]\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['B'].replace(to_replace = [6,8,5], value = [60,80,50], inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = df % 1 == 0 # pas trouvé mieux pour faire un masque rempli de 'True'\n",
    "m['B'] = False\n",
    "dfmod = df\n",
    "dfmod['A']=df['B']\n",
    "dfmod['B']=df['A']\n",
    "df.where(m, dfmod)\n",
    "#dfObj = pd.DataFrame(columns=['User_ID', 'UserName', 'Action'], index=['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(m, dfmod) # quand c'est un multiple de trois, laisser df, sinon mettre -df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des données pour l'indicateur région\n",
    "coucou1 = country_c.where(country_c[\"Region\"]=='Latin America & Caribbean').dropna(how = 'all', inplace=False)\n",
    "coucou2 = country_c[country_c[\"Region\"]=='Latin America & Caribbean']\n",
    "Diff(coucou, coucou2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coucou3 = country_c[country_c[\"Region\"].isnull()]\n",
    "coucou1.shape, coucou2.shape, coucou3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
